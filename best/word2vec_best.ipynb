{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPg458HBf6c-",
        "outputId": "3a2439c3-98db-4aef-fea6-89ed7ccc2d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2522, 2)\n",
            "First few rows:\n",
            "                                             QUESTION       BT LEVEL\n",
            "0  Suppose prices of two goods are constant, expl...  Understanding\n",
            "1  Explain the concept of price leadership observ...  Understanding\n",
            "2  Define profit. Briefly explain how accounting ...  Understanding\n",
            "3  Describe the assumptions of monopolistic compe...  Understanding\n",
            "4  Explain the meaning of the law of diminishing ...  Understanding\n",
            "RandomForest -> Precision: 0.793 / Recall: 0.388 / Accuracy: 0.513\n",
            "Precision: 0.605 / Recall: 0.354 / Accuracy: 0.469\n",
            "Precision: 0.224 / Recall: 0.174 / Accuracy: 0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.057 / Recall: 0.167 / Accuracy: 0.341\n",
            "Precision: 0.510 / Recall: 0.419 / Accuracy: 0.495\n",
            "Precision: 0.289 / Recall: 0.263 / Accuracy: 0.345\n",
            "Precision: 0.057 / Recall: 0.167 / Accuracy: 0.341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Bloom's Taxonomy Level Classification using Word2Vec and RandomForest.\"\"\"\n",
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/combined_dataset.csv\")\n",
        "\n",
        "# Display basic dataset info\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"First few rows:\\n\", df.head())\n",
        "\n",
        "# Preprocess text data\n",
        "df['CLEAN_QUESTION'] = df['QUESTION'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "\n",
        "# Map Bloom's Taxonomy levels to numerical values\n",
        "bt_level_mapping = {\n",
        "    'Remembering': 0,\n",
        "    'Understanding': 1,\n",
        "    'Applying': 2,\n",
        "    'Analyzing': 3,\n",
        "    'Evaluating': 4,\n",
        "    'Creating': 5\n",
        "}\n",
        "df['BT LEVEL'] = df['BT LEVEL'].map(bt_level_mapping)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['CLEAN_QUESTION'], df['BT LEVEL'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = gensim.models.Word2Vec(\n",
        "    sentences=X_train,\n",
        "    vector_size=100,\n",
        "    window=1,\n",
        "    min_count=2,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "# Function to compute average word vectors for a sentence\n",
        "def average_word_vectors(sentence, model, vector_size):\n",
        "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
        "\n",
        "# Convert sentences to vectors\n",
        "X_train_vect = np.array([average_word_vectors(sentence, w2v_model, 100) for sentence in X_train])\n",
        "X_test_vect = np.array([average_word_vectors(sentence, w2v_model, 100) for sentence in X_test])\n",
        "\n",
        "# Train RandomForest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_model = rf.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = rf_model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "# Example: Using Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize and train the model\n",
        "model = SVC(kernel='linear', random_state=42)\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "model = XGBClassifier(random_state=42)\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Bloom's Taxonomy Level Classification using Word2Vec and Various Classifiers.\"\"\"\n",
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/combined_dataset.csv\")\n",
        "\n",
        "# Display basic dataset info\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"First few rows:\\n\", df.head())\n",
        "\n",
        "# Preprocess text data\n",
        "df['CLEAN_QUESTION'] = df['QUESTION'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "\n",
        "# Map Bloom's Taxonomy levels to numerical values\n",
        "bt_level_mapping = {\n",
        "    'Remembering': 0,\n",
        "    'Understanding': 1,\n",
        "    'Applying': 2,\n",
        "    'Analyzing': 3,\n",
        "    'Evaluating': 4,\n",
        "    'Creating': 5\n",
        "}\n",
        "df['BT LEVEL'] = df['BT LEVEL'].map(bt_level_mapping)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['CLEAN_QUESTION'], df['BT LEVEL'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Word2Vec model on the entire dataset\n",
        "w2v_model = gensim.models.Word2Vec(\n",
        "    sentences=df['CLEAN_QUESTION'],\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "# Function to compute average word vectors for a sentence\n",
        "def average_word_vectors(sentence, model, vector_size):\n",
        "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
        "\n",
        "# Convert sentences to vectors\n",
        "X_train_vect = np.array([average_word_vectors(sentence, w2v_model, 100) for sentence in X_train])\n",
        "X_test_vect = np.array([average_word_vectors(sentence, w2v_model, 100) for sentence in X_test])\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=50)  # Reduce vector size\n",
        "X_train_pca = pca.fit_transform(X_train_vect)\n",
        "X_test_pca = pca.transform(X_test_vect)\n",
        "\n",
        "# Compute class weights for imbalance handling\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "# Train RandomForest with class weights\n",
        "rf = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
        "rf_model = rf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict and evaluate RandomForest\n",
        "y_pred = rf_model.predict(X_test_pca)\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('RandomForest -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(precision, recall, accuracy))\n",
        "\n",
        "\n",
        "# Train XGBoost with class weights\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "xgb.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict and evaluate XGBoost\n",
        "y_pred = xgb.predict(X_test_pca)\n",
        "print('XGBoost -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(\n",
        "    precision_score(y_test, y_pred, average=\"macro\"),\n",
        "    recall_score(y_test, y_pred, average=\"macro\"),\n",
        "    accuracy_score(y_test, y_pred)\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTrjmcz1f-9P",
        "outputId": "3a2e2c43-a2b5-4488-a525-5746aa439203"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2522, 2)\n",
            "First few rows:\n",
            "                                             QUESTION       BT LEVEL\n",
            "0  Suppose prices of two goods are constant, expl...  Understanding\n",
            "1  Explain the concept of price leadership observ...  Understanding\n",
            "2  Define profit. Briefly explain how accounting ...  Understanding\n",
            "3  Describe the assumptions of monopolistic compe...  Understanding\n",
            "4  Explain the meaning of the law of diminishing ...  Understanding\n",
            "RandomForest -> Precision: 0.874 / Recall: 0.421 / Accuracy: 0.543\n",
            "XGBoost -> Precision: 0.652 / Recall: 0.543 / Accuracy: 0.606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define parameter grids for hyperparameter tuning\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
        "    'solver': ['liblinear', 'saga'],  # Solvers for logistic regression\n",
        "    'max_iter': [1000, 2000, 3000]\n",
        "}\n",
        "\n",
        "param_grid_svc = {\n",
        "    'C': [0.1, 1, 10],  # Regularization strength\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
        "}\n",
        "\n",
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (150,)],  # Vary number of neurons\n",
        "    'max_iter': [1000, 2000],\n",
        "    'solver': ['adam', 'sgd'],  # Change optimizer\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# GridSearch for Logistic Regression\n",
        "lr_grid_search = GridSearchCV(LogisticRegression(class_weight='balanced', random_state=42), param_grid_lr, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "lr_grid_search.fit(X_train_pca, y_train)\n",
        "print(\"Best parameters for Logistic Regression:\", lr_grid_search.best_params_)\n",
        "\n",
        "# Train the best Logistic Regression model\n",
        "lr_best = lr_grid_search.best_estimator_\n",
        "lr_best.fit(X_train_pca, y_train)\n",
        "y_pred_lr = lr_best.predict(X_test_pca)\n",
        "print('Logistic Regression -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(\n",
        "    precision_score(y_test, y_pred_lr, average=\"macro\"),\n",
        "    recall_score(y_test, y_pred_lr, average=\"macro\"),\n",
        "    accuracy_score(y_test, y_pred_lr)\n",
        "))\n",
        "\n",
        "# GridSearch for SVC\n",
        "svc_grid_search = GridSearchCV(SVC(class_weight='balanced', random_state=42), param_grid_svc, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "svc_grid_search.fit(X_train_pca, y_train)\n",
        "print(\"Best parameters for SVC:\", svc_grid_search.best_params_)\n",
        "\n",
        "# Train the best SVC model\n",
        "svc_best = svc_grid_search.best_estimator_\n",
        "svc_best.fit(X_train_pca, y_train)\n",
        "y_pred_svc = svc_best.predict(X_test_pca)\n",
        "print('SVC -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(\n",
        "    precision_score(y_test, y_pred_svc, average=\"macro\"),\n",
        "    recall_score(y_test, y_pred_svc, average=\"macro\"),\n",
        "    accuracy_score(y_test, y_pred_svc)\n",
        "))\n",
        "\n",
        "# GridSearch for KNN\n",
        "knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "knn_grid_search.fit(X_train_pca, y_train)\n",
        "print(\"Best parameters for KNN:\", knn_grid_search.best_params_)\n",
        "\n",
        "# Train the best KNN model\n",
        "knn_best = knn_grid_search.best_estimator_\n",
        "knn_best.fit(X_train_pca, y_train)\n",
        "y_pred_knn = knn_best.predict(X_test_pca)\n",
        "print('KNN -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(\n",
        "    precision_score(y_test, y_pred_knn, average=\"macro\"),\n",
        "    recall_score(y_test, y_pred_knn, average=\"macro\"),\n",
        "    accuracy_score(y_test, y_pred_knn)\n",
        "))\n",
        "\n",
        "# GridSearch for MLP (without class_weight)\n",
        "mlp_grid_search = GridSearchCV(MLPClassifier(random_state=42), param_grid_mlp, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "mlp_grid_search.fit(X_train_pca, y_train)\n",
        "print(\"Best parameters for MLP:\", mlp_grid_search.best_params_)\n",
        "\n",
        "# Train the best MLP model\n",
        "mlp_best = mlp_grid_search.best_estimator_\n",
        "mlp_best.fit(X_train_pca, y_train)\n",
        "y_pred_mlp = mlp_best.predict(X_test_pca)\n",
        "print('MLP -> Precision: {:.3f} / Recall: {:.3f} / Accuracy: {:.3f}'.format(\n",
        "    precision_score(y_test, y_pred_mlp, average=\"macro\"),\n",
        "    recall_score(y_test, y_pred_mlp, average=\"macro\"),\n",
        "    accuracy_score(y_test, y_pred_mlp)\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9baEv9Ai5UB",
        "outputId": "18d1988c-8ee2-4675-a4d8-30af89c702da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 0.01, 'max_iter': 1000, 'solver': 'liblinear'}\n",
            "Logistic Regression -> Precision: 0.115 / Recall: 0.197 / Accuracy: 0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for SVC: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "SVC -> Precision: 0.299 / Recall: 0.250 / Accuracy: 0.311\n",
            "Best parameters for KNN: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "KNN -> Precision: 0.392 / Recall: 0.341 / Accuracy: 0.410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWVpGJSfi5_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}